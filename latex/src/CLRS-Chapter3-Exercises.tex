\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
 
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\numberwithin{equation}{section}
\setlength{\parindent}{0em}

\lstset{
  language=C++,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\small\color{blue},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4
}

\author{JÃ¶rg Barkoczi}
\title{\vspace{-2.0cm}Chapter 3 Exercise Solutions}
\date{ }

\newtheorem{theorem}{Theorem}

% change \iff to the shorter version
\renewcommand{\iff}{\Leftrightarrow}
\renewcommand{\implies}{\Rightarrow}

\begin{document}
\maketitle

\setcounter{section}{2}
\section{}

% redundant but for consistency
\setcounter{subsection}{0}
\subsection{}

% set style to match CLRS
\renewcommand{\thesubsubsection}{\thesubsection-\arabic{subsubsection}}
\subsubsection{}
Let $f(n)$ and $g(n)$ be asymptotically nonnegative functions. Using the basic
definition of $\Theta$-notation, prove that $max(f(n), g(n)) = \Theta (f(n) + g(n))$.
\\~

Given constants $c_1$, $c_2$ and $n_0$, a function $(m(n) = max(f(n), g(n))) \in
\Theta (f(n) + g(n))$ if and only if $ 0 \leq c_1(f(n) + g(n)) \leq m(n) \leq c_2(f(n) + g(n))$.
Since $m(n) \leq f(n) + g(n)$ we already have an upper bound to work with and can thus default
$c_2$ to just $1$.

For the lower bound we can just take the factor $min({\frac{f(n)}{f(n) + g(n)}, \frac{g(n)}{f(n) + g(n)}})$, which
shrinks the expression $f(n) + g(n)$ to $min(f(n), g(n))$ and therefore is always smaller or equal to $max(f(n), g(n))$.

And thus our function $m(n)$ satisfies $0 \leq min({\frac{f(n)}{f(n) + g(n)}, \frac{g(n)}{f(n) + g(n)}}) (f(n) + g(n))
\leq m(n) \leq f(n) + g(n), \forall n > 0$ and is indeed in the set of functions described by $\Theta(f(n) + g(n))$.

\subsubsection{}
Show that for any real constants $a$ and $b$, where $b > 0$,
\[(n+a)^b = \Theta(n^b).\]

Let us start by showing that $(n+a)^b = O(n^b)$. This requires us to find constants $c, n_0$
such that 
\[0 \leq (n+a)^b \leq cn^b, \forall n \geq n_0.\]\\
Let $c = 2^b$ 
\[\iff (n+a)^b \leq (2n)^b\]
and thus we have $(n+a)^b \leq (2n)^b, \forall n \geq n_0 = |a|$ which implies 
\[(n+a)^b = O(n^b).\]

Next we need to show that $(n+a)^b = \Omega(n^b)$, which again 
requires us to find constants $c, n_0$ such that
\[0 \leq cn^b \leq (n+a)^b, \forall n \geq n_0.\]\\
Let $c=(\frac{1}{2})^b$.
\begin{equation*}
    \begin{split}
        \Rightarrow (n+a)^b & \geq (\frac{1}{2}n)^b\\
    \end{split}
\end{equation*}
and thus we have $(n+a)^b \geq (\frac{1}{2}n)^b, \forall n \geq n_0 = 2|a|$ which implies 
\[(n+a)^b = \Omega(n^b).\]
And therefore, by Theorem 3.1, $(n+a)^b = \Theta(n^b)$.

\subsubsection{}
Explain why the statement, ``The running time of algorithm A
is at least $O(n^2)$'', is meaningless.
~\\

Saying that the running time of algorithm A is at least $O(n^2)$ gives
no information about the worst-case running time, because ``at least''
implies the best-case input.
It gives no information on the best-case running time either, since
the $O$-notation bounds a function from the above, not from below as 
the $\Omega$-notation does. Therefore the statement is to be considered
meaningless.

\subsubsection{}
Is $2^{n+1} = O(2^n)$?\\

Inequality to prove: \[0 \leq 2^{n+1} \leq c \cdot 2^n, \forall n \geq n_0.\]
Let $c = 2$, then
\[2^{n+1} \leq 2 \cdot 2^n = 2^{n+1}, \forall n \geq 0.\]
Therefore $2^{n+1} = O(n^2)$.\\
\pagebreak
~\\
Is $2^{2n} = O(2^n)$?
~\\~\\
Inequality to prove: \[0 \leq 2^{2n} \leq c \cdot 2^n, \forall n \geq n_0.\]
\begin{equation*}
    \begin{split}
        2^{2n} & \leq c \cdot 2^n\\
        2^{n} & \leq c\\
    \end{split}
\end{equation*}
There is obviously no constant $c$ that satisfies
\[\lim_{n \to \infty} 2^{n} \leq c,\]
therefore $2^{2n} \neq O(2^n)$.

\subsubsection{}
Prove Theorem 3.1.
~\\~\\
``For any two functions $f(n)$ and $g(n)$, we have $f(n) = \Theta(g(n))$
if and only if $f(n) = O(g(n))$ and $f(n) = \Omega(g(n))$'' (Theorem 3.1).\\

Per definition $\Theta(g(n))$ requires the existence of constants $c_1, c_2, n_0$ 
such that \[0 \leq c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n), \forall n \geq n_0.\]
Therefore we can split of the inequalities as 
\[0 \leq c_1 \cdot g(n) \leq f(n), \forall n \geq n_0,\] which implies $f(n) = \Omega(n)$, and
\[0 \leq f(n) \leq c_2 \cdot g(n), \forall n \geq n_0,\] which implies $f(n) = O(n)$.\\

From the other side of the equivalence, if we have constants $c_a, c_b, n_a, n_b$ such that
\[0 \leq c_a \cdot g(n) \leq f(n), \forall n \geq n_a,\] and
\[0 \leq f(n) \leq c_b \cdot g(n), \forall n \geq n_b,\]
we can let $n_0 = max(n_a, n_b)$ and thus satisfy 
\[0 \leq c_a \cdot g(n) \leq f(n) \leq c_b \cdot g(n), \forall n \geq n_0.\]

\subsubsection{}
Prove that the running time of an algorithm is $\Theta(g(n))$ if and only if 
its worst-case running time is $O(g(n))$ and its best-case running time 
is $\Omega(g(n))$.\\

If the worst-case running time of an algorithm is $O(g(n))$, the implication
is that the running time is bounded from above (by some funtion $f(n) = O(g(n))$)
for any input of size $n$.\\
Likewise if the best-case running time of an algorithm is $\Omega(g(n))$, the
implication is that the running time is bounded from below (by some function
$f(n) = \Omega(g(n))$) for any input of size $n$.\\
Therefore by Theorem 3.1, that algorithm's running time is $\Theta(g(n))$.\\

Written as an equivalence:
~\\
\begin{equation*}
    \begin{split}
         f(n) \in \Theta(g(n))\\
        & \iff \exists c_1, c_2, n_0 : 0 \leq c_1 g(n) \leq 
            f(n) \leq c_2 g(n), \forall n \geq n_0\\
        & \iff (0 \leq c_1 g(n)
            \leq f(n) \land 0 \leq f(n) \leq c_2 g(n)), \forall n \geq n_0\\
        & \iff f(n) \in \Omega(g(n)) \cap O(g(n))\\
    \end{split}
\end{equation*}

\subsubsection{}
Prove that $o(g(n)) \cap \omega(g(n))$ is the empty set.\\

For a function $f(n)$ to be considered a member of $o(g(n)) \cap \omega(g(n))$,
the following equivalence must be true:
\begin{equation*}
    \begin{split}
        & f(n) \in \omega(g(n)) \cap o(g(n))\\
        & \iff 0 \leq c_1 g(n) < f(n) \land 0 \leq f(n) < c_2 g(n)\\
        & \iff 0 \leq c_1 g(n) < f(n) < c_2 g(n)\\
    \end{split}
\end{equation*}
for all positive real constants $c_1$ and $c_2$, and for all $n$ bigger than
some positive constant $n_0$.\\
But since $c_1 g(n) < c_2 g(n)$ can't be true for all positive constants
$c_1$ and $c_2$, $o(g(n)) \cap \omega(g(n))$ must be the empty set.

\pagebreak
\subsubsection{}
\[O(g(n,m)) = \{ f(n,m) : \exists c,n_0, m_0 > 0 :
    0 \leq f(n,m) \leq cg(n,m), \forall n \geq n_0 \lor \forall m \geq m_0 \} \] 

\[\Omega(g(n,m)) = \{ f(n,m) : \exists c,n_0, m_0 > 0 :
    0 \leq cg(n,m) \leq f(n,m), \forall n \geq n_0 \lor \forall m \geq m_0 \} \] 

\[\Theta(g(n,m)) = \{ f(n,m) : f(n,m) \in \Omega(g(n,m)) \cap O(g(n,m)) \} \] 

\subsection{}
\subsubsection{}
Show that if $f(n)$ and $g(n)$ are monotonically increasing functions, then so are
the functions $f(n) + g(n)$ and $f(g(n))$, and if $f(n)$ and $g(n)$ are in addition
nonnegative, then $f(n) \cdot g(n)$ is monotonically increasing.\\

$f(n)$ and $g(n)$ being monotonically increasing implies that for $n \leq m$ 
\begin{equation*}
    \begin{split}
        & f(n) \leq f(m) \land g(n) \leq g(m)\\
        & \iff f(n) + g(m) \geq f(n) + g(n)\\
        & \iff f(m) + g(m) \geq f(n) + g(n),\\
    \end{split}
\end{equation*}

likewise it implies that $f(g(n)) \leq f(g(m))$.\\
If in addition both $f(n)$ and $g(n)$ are nonnegative, 
the following holds
\begin{equation*}
    \begin{split}
        & f(n)g(n) = f(n)g(n)\\
        & \iff f(n)g(n) \leq f(n)g(m)\\
        & \iff f(n)g(n) \leq f(m)g(m)\\
    \end{split}
\end{equation*}

\subsubsection{}
Proof equation (3.16).
\begin{equation}\tag{3.16}
    a^{\log_b c} = c^{\log_b a}
\end{equation}

\[
    \begin{split}
        & a^{\log_b c} = c^{\log_b a}             \\
        & \iff a^{\frac{\log_b c}{ \log_b a}} = c \\
        & \iff a^{\log_a c} = c                   \\
        & \iff c = c
    \end{split}
\]

\subsubsection{}
Prove equation 3.19 $\lg(n!) = \Theta(n \lg n)$. Also prove that
$n! = \omega(2^n)$ and $n! = o(n^n)$.\\

Let us start with equation \textbf{3.19} and by showing its membership
to $O(n \lg n)$.

Let $c$ be some positive real constant, then
\[
\begin{split}
    & \lg(n!) \in O(n \lg n) \\
    & \iff 0 \leq \lg(n!) \leq c n \lg n \\
    & \iff \lg (n^n) \leq c n \lg n \\
    & \iff n \lg n \leq c n \lg n
\end{split}
\]
holds for all $n \geq n_0 = 1$ if $c >= 1$.\\

Now we will need to additionally show that $\lg(n!)$ is also
a member of $\Omega(n \lg n)$.
Again let $c$ be some positive real constant, then
\[
\begin{split}
    & \lg(n!) \in \Omega(n \lg n) \\
    & \iff 0 \leq c n \lg n \leq \lg(n!), \; \forall n > n_0.\\
\end{split}
\]
By Sterling's approximation we have
\[
\begin{split}
    & c n \lg n \leq \lg(n!)\\
    & \iff cn \lg n
        \leq \lg \left(\sqrt{2\pi n}\left(\frac{n}{e}\right)^n \cdot e \right) \\
    & \iff cn \lg n \leq \frac{1}{2} (\lg {2\pi} + \lg n) + n\lg n - n\lg e + \lg e.\\
\end{split}
\]
Let $c = 0.5$, then we have
\[
\begin{split}
    0 \leq \frac{1}{2} (\lg {2\pi} + \lg n) + \frac{n}{2} \lg n - n\lg e + \lg e, 
\end{split}
\]
which is positive as long as $\frac{n}{2} \lg n - n\lg e$ is positive.\\
\pagebreak

Therefore 
\[
\begin{split}
    & \frac{n}{2} \lg n - n\lg e \geq 0\\
    & \iff \frac{n}{2} (\lg n - 2\lg e) \geq 0\\
    & \iff \lg n - 2\lg e \geq 0\\
    & \iff n \geq 2^{2\lg e},\\
\end{split}
\]
and thus there exists $c = 0.5$ such that 
\[
    0 \leq \frac{1}{2} (\lg {2\pi} + \lg n) + \frac{n}{2} \lg n - n\lg e + \lg e, 
\]
for all $n \geq n_0 = 2^{2 \lg e}$, and therefore $\lg (n!)$ is 
also element of $\Omega (n \lg n)$, which by Theorem 3.1 is equivalent to
$\lg(n!) \in \Theta(n \lg n)$.\\

\textit{Prove} $n! = o(n^n)$.

We need to show that
\[
    \lim_{n \to \infty} \frac{n^n}{n!} = \infty,
\]
or alternatively 
\[
    \lim_{n \to \infty} \frac{n!}{n^n} = 0.
\]

We can again make use of Sterling's approximation, such that we have
\[
\begin{split}
    & \frac{n^n}{\sqrt{2\pi n} {\left(\frac{n}{e}\right)}^n 
            \left(1+\Theta(\frac{1}{n})\right)} \\
    =& \frac{e^n}{\sqrt{2\pi n} \left(1+\Theta \left(\frac{1}{n}\right)\right)} \\
    =& \frac{e^n}{\sqrt{2\pi n} \Theta\left(\frac{\sqrt{2\pi n}}{n}\right)} \\
    =& \frac{e^n}{\Theta\left(\frac{{\sqrt{2\pi n}}^2}{n}\right)} \\
    =& \frac{e^n}{\Theta (2 \pi)} \\
    =& \frac{e^n}{\Theta (1)} \\
\end{split}
\]
now looking at the limit we have
\[
    \lim_{n \to \infty} \frac{e^n}{\Theta (1)} = \infty.
\]

\pagebreak
\textit{Prove} $n! = w(n^n)$.

We need to show that
\[
    \lim_{n \to \infty} \frac{2^n}{n!} = 0,
\]
or alternatively 
\[
    \lim_{n \to \infty} \frac{n!}{2^n} = \infty.
\]
Using Sterling's approximation again, we get 
\[
\begin{split}
    & \frac{2^n} {\sqrt{2\pi n}{\left(\frac{n}{e}\right)}^n 
            \left(1+\Theta(\frac{1}{n})\right)} \\
    =& \frac{{(2e)}^n} {\sqrt{2\pi n} \, n^n
            \left(1+\Theta(\frac{1}{n})\right)} \\
    =& \frac{{(2e)}^n} {\sqrt{2\pi n} \left( n^n + \Theta(n^{n-1})\right)} \\
    =& \frac{{(2e)}^n} {\sqrt{2\pi n} \Theta(n^{n-1})} \\
    =& \frac{{(2e)}^n} {\sqrt{2\pi n} \Theta(n^{n})} \\
    =& \frac{{(2e)}^n} {\Theta(\sqrt{n}) \Theta(n^{n})} \\
    =& \frac{{(2e)}^n} {\Theta(\sqrt{n} \, n^{n})} \\
    =& \frac{{(2e)}^n} {\Theta(n^{n + \frac{1}{2}})} \\
    =& \frac{2e} {\Theta(n^{2n^{-1} + 1})} \\
\end{split}
\]
Now looking at the limit, we have
\[
    \lim_{n\to\infty} \frac{2e}{\Theta(n^{2n^{-1}+1})} = \frac{2e}{n} = 0.
\]

\subsubsection{}
Is the function $\lceil \lg n \rceil!$ polynomially bounded? Is the function 
$\lceil \lg \lg n \rceil!$ polynomially bounded?

\subsubsection{}
Which is asymptotically larger: $\lg(\lg* n)$ or $\lg*(\lg n)$?

\subsubsection{}
Show that the golden ratio $\phi$ and its $\widehat{\phi}$ both
satify the equation $x^2 = x + 1$.

We can show this by using the quadratic formula: 
\begin{alignat*}{1}
    x_{1,2} &= \frac{1}{2} \pm \sqrt{{-\frac{1}{2}}^2 + 1}\\
             &= \frac{1}{2} \pm \sqrt{\frac{5}{4}}\\
             &= \frac{1}{2} \pm \frac{\sqrt{5}}{2}\\
\end{alignat*}
Therefore the first solution to the equation is $\frac{1-\sqrt{5}}{2} = \widehat{\phi}$
and the second is $\frac{1+\sqrt{5}}{2} = \phi$.

\subsubsection{}
Prove by induction that the $i$th Fibonacci number satisfies the 
equality
\[
    F_i = \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}},
\]
where $\phi$ is the golden ratio and $\widehat{\phi}$ is its conjugate.

First we show that it holds for $i=1$ and $i=2$.
\begin{alignat*}{1}
    F_1 &= \frac{\phi^1 - \widehat{\phi^1}}{\sqrt{5}}\\
        &= \frac{\frac{1+\sqrt{5}}{2} - \frac{1-\sqrt{5}}{2}}{\sqrt{5}}\\
        &= \frac{1+\sqrt{5} - (1-\sqrt{5})} {2\sqrt{5}}\\
        &= \frac{2\sqrt{5}} {2\sqrt{5}} = 1
\end{alignat*}
\begin{alignat*}{1}
    F_2 &= \frac{\phi^2 - \widehat{\phi^2}} {\sqrt{5}}\\
        &= \frac{(\frac{1+\sqrt{5}}{2})^2 - (\frac{1-\sqrt{5}}{2})^2} {\sqrt{5}}\\
        &= \frac{(1+\sqrt{5})^2 - (1-\sqrt{5})^2} {4\sqrt{5}}\\
        &= \frac{1+2\sqrt{5}+5 - (1-2\sqrt{5}+5)} {4\sqrt{5}}\\
        &= \frac{4\sqrt{5}} {4\sqrt{5}} = 1\\
\end{alignat*}
Now assuming that the equality holds for $F_{i-2}$ and $F_{i-1}$, we 
will show that it also holds for $F_i$ by showing that $F_i = F_{i-2} + F_{i-1}$
as this is the property of the Fibonacci sequence.
\begin{alignat*}{1}
    && F_i &= F_{i-2} + F_{i-1}\\
    \iff&& \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}}
            &= \frac{\phi^{i-2} - \widehat{\phi}^{i-2}}{\sqrt{5}}
            +  \frac{\phi^{i-1} - \widehat{\phi}^{i-1}}{\sqrt{5}}\\
    \iff&& \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}}
            &= \frac{\phi^{i-2} - \widehat{\phi}^{i-2}
            + \phi^{i-1} - \widehat{\phi}^{i-1}} {\sqrt{5}}\\
    \iff&& \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}}
            &= \frac{\phi^{i-1} + \phi^{i-2} - \widehat{\phi}^{i-1}
             - \widehat{\phi}^{i-2}} {\sqrt{5}}\\
    \iff&& \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}}
            &= \frac{\phi^{i-2} (\phi^{1} + 1) 
            - \widehat{\phi}^{i-2}(\widehat{\phi}^{1}+1)} {\sqrt{5}}\\
    \iff&& \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}}
            &= \frac{\phi^{i-2} (\phi^2) 
            - \widehat{\phi}^{i-2}(\widehat{\phi}^2)} {\sqrt{5}}\\
    \iff&& \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}}
            &= \frac{\phi^i - \widehat{\phi^i}}{\sqrt{5}}\\
\end{alignat*}

\pagebreak
\subsubsection{}
Show that $k\ln k = \Theta(n)$ implies $k = \Theta\left(\frac{n}{\ln n}\right)$.\\

If $k\ln k = \Theta(n)$, then given positive constants $c_1,c_2,n_0$, we have that
\[
    0 \leq c_1 n \leq k \ln k \leq c_2 n,
\]
is true for all $n \geq n_0$. Now suppose that $k = \frac{n}{\ln n} = \Theta(\frac{n}{\ln n})$.
When substituting in the above equation we get 
\[
    0 \leq c_1 n \leq \frac{n}{\ln n} \ln \left(\frac{n}{\ln n}\right) \leq c_2 n.
\]
If we can show that this equation holds for the given constants, we see that 
$k\ln k = \Theta(n)$ does indeed imply $k = \Theta\left(\frac{n}{\ln n}\right)$.\\
Let $f(n) := \frac{n}{\ln n} \ln \left(\frac{n}{\ln n}\right)$. We will first show that
$f(n) \in O(n)$. To show this we need constants $c_2, n_0$ such that 
\[
    0 \leq f(n) \leq c_2 n,
\]
for all $n\geq n_0$.
\begin{alignat*}{2}
    && 0 \leq f(n) \leq c_2 n\\
    \iff&& \frac{n}{\ln n} \ln \left(\frac{n}{\ln n}\right)  \leq c_2 n\\
    \iff&& \frac{n}{\ln n} \cdot \left( \ln n - \ln \ln n\right) \leq c_2 n\\
    \iff&& n -\frac{n}{\ln n} \ln \ln n \leq c_2 n\\
\end{alignat*}
This holds for $c_2 = 1$ as long as $\frac{n}{\ln n} \ln \ln n$ is nonnegative.
So we either must have that both $\frac{n}{\ln n}$ and $\ln\ln n$ are negative, or that
both are positive. Since $n$ is always nonnegative, $\ln n$ must be negative for $\frac{n}{\ln n}$
to be negative, and $\ln n$ is negative for $n \in (0,1)$. On the other hand we have that $\ln \ln n$
is negative precisely when $0 < \ln n < 1$, which is true for $n \in (1, e)$. Thus both expressions can't 
be negative at the same time and both must therefore be positive, which is true for $n \geq e$.\\ Thus
$\frac{n}{\ln n} \ln \left(\frac{n}{\ln n}\right)  \leq c_2 n$ for $c_2 = 1$ and $n \geq n_0 = e$ and therefore
$f(n) \in O(n)$.\\
Now we will show that $f(n) \in \Omega(n)$ is true aswell. To show this we need constants $c_1, n_0$ such that
\[
    0 \leq c_1n \leq f(n),
\]
for all $n\geq n_0$.

\begin{alignat*}{2}
    && 0 \leq c_1 n \leq f(n) n\\
    \iff&& c_2 n \leq n -\frac{n}{\ln n} \ln \ln n\\
    \iff&& c_2 \leq 1 -\frac{1}{\ln n} \ln \ln n\\
    \iff&& c_2 -1 \leq -\frac{1}{\ln n} \ln \ln n\\
    \iff&& \frac{1}{\ln n} \ln \ln n \leq -c_2 + 1\\
    \iff&& \frac{\ln \ln n}{\ln n}  \leq -c_2 + 1\\
    \iff&& e^{\left(\frac{\ln \ln n}{\ln n}\right)}  \leq e^{(-c_2 + 1)}\\
    \iff&& {(e^{\left(\ln \ln n\right)})}^{\frac{1}{\ln n}} \leq e^{(-c_2 + 1)}\\
    \iff&& {(\ln n)}^{\frac{1}{\ln n}} \leq e^{(-c_2 + 1)}\\
    \iff&& \ln n \leq {(e^{(-c_2 + 1)})}^\ln n\\
    \iff&& \ln n \leq e^{(-c_2 + 1) \cdot \ln n}\\
    \iff&& \ln n \leq e^{-c_2 \ln n + \ln n}\\
    \iff&& \ln n \leq e^{-c_2 \ln n} n\\
    \iff&& \ln n \leq n^{-c_2} n\\
    \iff&& n \leq e^{n^{-c_2} n}\\
    \iff&& n \leq e^{\frac{n}{n^{c_2}}}\\
\end{alignat*}
We have that 
\[
    \lim_{c_2 \to 0} e^{\frac{n}{n^{c_2}}} = e^{n},
\]
which shows that the inequality holds for small choices of $c_2$. It is not difficult to 
show it for concrete values of $c_2$ by comparing an initial value and the gradients. 
Therefore $f(n) = \frac{n}{\ln n} \ln \left(\frac{n}{\ln n}\right) \in \Omega(n)$. Since
it also a member of $O(n)$ as we showed before, it follows that $f(n) \in \Theta(n)$ is true,
which implies that $k = \frac{n}{\ln n} \in \Theta(\frac{n}{\ln n})$ is also true.

\end{document}
